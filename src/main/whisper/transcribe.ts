import { spawn, ChildProcess } from 'child_process'
import { join, dirname } from 'path'
import { mkdirSync, readFileSync, writeFileSync } from 'fs'
import { unlink } from 'fs/promises'
import { cpus } from 'os'
import axios from 'axios'
import { createWriteStream } from 'fs'
import { app } from 'electron'
import type { BrowserWindow } from 'electron'
import { getWhisperExe, isBinaryDownloaded, downloadBinary, isGpuEnabled } from './binary'
import { getModelPath, getModelUrl, isModelDownloaded, getModelDir } from './models'
import { getFfmpegPath, sumDurations } from '../ffmpeg/probe'
import { createTempDir, createConcatListFile, cleanupTempDir } from '../ffmpeg/concat'
import { parseSilences, buildSegments, offsetSrtContent, mergeSrts, secondsToTimestamp } from './segments'
import type { WhisperModel, WhisperProgress } from '../../shared/types'
import { IPC } from '../../shared/types'

let activeProcess: ChildProcess | null = null
let activeAbortController: AbortController | null = null

function send(win: BrowserWindow, progress: WhisperProgress): void {
  win.webContents.send(IPC.WHISPER_PROGRESS, progress)
}

function hhmmssToSeconds(time: string): number {
  const parts = time.split(':').map(parseFloat)
  return parts[0] * 3600 + parts[1] * 60 + parts[2]
}

// Use as many threads as logical CPUs, capped at 8 (diminishing returns beyond that)
function getThreadCount(): number {
  return Math.max(1, Math.min(cpus().length, 8))
}

async function downloadModel(
  model: WhisperModel,
  win: BrowserWindow,
  signal?: AbortSignal
): Promise<void> {
  const modelDir = getModelDir()
  mkdirSync(modelDir, { recursive: true })

  const modelPath = getModelPath(model)
  const url = getModelUrl(model)

  const response = await axios.get(url, {
    responseType: 'stream',
    maxRedirects: 10,
    headers: { 'User-Agent': 'VideoBookForge' },
    signal
  })

  const total = parseInt(response.headers['content-length'] || '0', 10)
  let downloaded = 0

  await new Promise<void>((resolve, reject) => {
    const writer = createWriteStream(modelPath)

    const onAbort = (): void => {
      writer.destroy()
      unlink(modelPath).catch(() => {})
      reject(new Error('Cancelled'))
    }
    signal?.addEventListener('abort', onAbort, { once: true })

    response.data.on('data', (chunk: Buffer) => {
      downloaded += chunk.length
      if (total > 0) {
        const pct = Math.round((downloaded / total) * 100)
        send(win, {
          phase: 'downloading-model',
          percent: pct,
          message: `Downloading model... ${pct}%`
        })
      }
    })
    response.data.pipe(writer)
    writer.on('finish', () => {
      signal?.removeEventListener('abort', onAbort)
      if (signal?.aborted) {
        unlink(modelPath).catch(() => {})
        reject(new Error('Cancelled'))
      } else {
        resolve()
      }
    })
    writer.on('error', (err) => {
      signal?.removeEventListener('abort', onAbort)
      unlink(modelPath).catch(() => {})
      reject(err)
    })
  })
}

export async function transcribeAudio(
  win: BrowserWindow,
  audioPaths: string[],
  model: WhisperModel,
  promptText?: string
): Promise<string> {
  // Abort any previously running transcription before starting a new one
  activeAbortController?.abort()

  const abortController = new AbortController()
  activeAbortController = abortController
  const { signal } = abortController

  let tempDir: string | null = null

  try {
    // Step 1: Download whisper binary if needed
    if (!isBinaryDownloaded()) {
      send(win, { phase: 'downloading-binary', percent: 0, message: 'Downloading whisper.cpp...' })
      await downloadBinary((percent, message) => {
        if (!signal.aborted) send(win, { phase: 'downloading-binary', percent, message })
      }, signal)
    }

    if (signal.aborted) throw new Error('Cancelled')

    // Step 2: Download model if needed (also re-downloads if the file is incomplete)
    if (!isModelDownloaded(model)) {
      await unlink(getModelPath(model)).catch(() => {})
      send(win, { phase: 'downloading-model', percent: 0, message: 'Downloading model...' })
      await downloadModel(model, win, signal)
    }

    if (signal.aborted) throw new Error('Cancelled')

    const gpuEnabled = isGpuEnabled()

    // Step 3: Probe input files for total duration
    const totalDuration = await sumDurations(audioPaths)

    if (signal.aborted) throw new Error('Cancelled')

    // Step 4: Build concat list and create temp directory
    tempDir = await createTempDir()
    const listPath = await createConcatListFile(audioPaths, tempDir)
    const fullWavPath = join(tempDir, 'full.wav')

    const outputDir = join(app.getPath('userData'), 'whisper', 'output')
    mkdirSync(outputDir, { recursive: true })
    const srtBase = join(outputDir, `transcript_${Date.now()}`)
    const srtPath = `${srtBase}.srt`

    const ffmpeg = getFfmpegPath()
    const whisperExe = getWhisperExe()!
    const modelPath = getModelPath(model)
    const threads = getThreadCount()

    // ── Phase: preparing ─────────────────────────────────────────────────────
    // Convert all audio files to a single 16kHz mono WAV on disk.
    // This enables O(1) PCM seeking during segment extraction.
    send(win, { phase: 'preparing', percent: 0, message: 'Preparing audio...', totalDuration })

    await new Promise<void>((resolve, reject) => {
      const ffmpegProc = spawn(ffmpeg, [
        '-hide_banner', '-y',
        '-f', 'concat', '-safe', '0', '-i', listPath,
        '-ar', '16000', '-ac', '1', '-c:a', 'pcm_s16le',
        fullWavPath
      ])
      activeProcess = ffmpegProc

      const onAbort = (): void => { ffmpegProc.kill('SIGTERM') }
      signal.addEventListener('abort', onAbort, { once: true })

      let ffmpegErr = ''
      ffmpegProc.stderr?.on('data', (chunk: Buffer) => {
        const text = chunk.toString()
        ffmpegErr += text
        if (totalDuration > 0) {
          const m = text.match(/time=(\d+):(\d+):(\d+)/)
          if (m) {
            const elapsed = parseInt(m[1]) * 3600 + parseInt(m[2]) * 60 + parseInt(m[3])
            const pct = Math.min(Math.round((elapsed / totalDuration) * 100), 99)
            send(win, { phase: 'preparing', percent: pct, message: 'Preparing audio...', elapsed, totalDuration })
          }
        }
      })

      ffmpegProc.on('close', (code) => {
        signal.removeEventListener('abort', onAbort)
        activeProcess = null
        if (signal.aborted) return
        if (code === 0) resolve()
        else reject(new Error(`Audio prep failed (${code})\n${ffmpegErr.slice(-500)}`))
      })
      ffmpegProc.on('error', reject)
    })

    if (signal.aborted) throw new Error('Cancelled')

    // ── Phase: segmenting ─────────────────────────────────────────────────────
    // Run silencedetect on the full WAV to find natural speech boundaries.
    send(win, { phase: 'segmenting', percent: 0, message: 'Detecting audio segments...' })

    const silences = await new Promise<[number, number][]>((resolve, reject) => {
      const silProc = spawn(ffmpeg, [
        '-hide_banner',
        '-i', fullWavPath,
        '-af', 'silencedetect=n=-35dB:d=1.2',
        '-f', 'null', '-'
      ])
      activeProcess = silProc

      const onAbort = (): void => { silProc.kill('SIGTERM') }
      signal.addEventListener('abort', onAbort, { once: true })

      let stderr = ''
      silProc.stderr?.on('data', (chunk: Buffer) => { stderr += chunk.toString() })

      silProc.on('close', () => {
        signal.removeEventListener('abort', onAbort)
        activeProcess = null
        resolve(parseSilences(stderr))
      })
      silProc.on('error', reject)
    })

    if (signal.aborted) throw new Error('Cancelled')

    const segments = buildSegments(silences, totalDuration)
    send(win, {
      phase: 'segmenting',
      percent: 100,
      message: `Found ${segments.length} segment${segments.length !== 1 ? 's' : ''}`
    })

    // ── Phase: transcribing ───────────────────────────────────────────────────
    // Transcribe each segment sequentially, offset timestamps, then merge.
    const srtContents: string[] = []

    for (const seg of segments) {
      if (signal.aborted) throw new Error('Cancelled')

      const segPad = seg.index.toString().padStart(3, '0')
      const segWavPath = join(tempDir, `segment_${segPad}.wav`)
      const segSrtBase = join(tempDir, `segment_${segPad}`)

      // Extract segment WAV from the full PCM WAV (O(1) seek)
      await new Promise<void>((resolve, reject) => {
        const extractProc = spawn(ffmpeg, [
          '-hide_banner', '-y',
          '-ss', String(seg.startSec),
          '-t', String(seg.durationSec),
          '-i', fullWavPath,
          '-c:a', 'copy',
          segWavPath
        ])
        activeProcess = extractProc

        const onAbort = (): void => { extractProc.kill('SIGTERM') }
        signal.addEventListener('abort', onAbort, { once: true })

        extractProc.on('close', (code) => {
          signal.removeEventListener('abort', onAbort)
          activeProcess = null
          if (signal.aborted || code === 0) resolve()
          else reject(new Error(`Segment extract failed (code ${code})`))
        })
        extractProc.on('error', reject)
      })

      if (signal.aborted) throw new Error('Cancelled')

      // Build whisper-cli args — force English for speed, add prompt if available
      const whisperArgs: string[] = [
        '-m', modelPath,
        '-f', segWavPath,
        '-osrt', '-of', segSrtBase,
        '-l', 'en',       // force English — skips language detection, 10-30% faster
        '-pp',
        '-t', String(threads)
      ]
      if (promptText) whisperArgs.push('--prompt', promptText)

      await new Promise<void>((resolve, reject) => {
        const whisperProc = spawn(whisperExe, whisperArgs, { cwd: dirname(whisperExe) })
        activeProcess = whisperProc

        const onAbort = (): void => { whisperProc.kill('SIGTERM') }
        signal.addEventListener('abort', onAbort, { once: true })

        // whisper-cli writes progress to stderr
        whisperProc.stderr?.on('data', (chunk: Buffer) => {
          const text = chunk.toString()
          const progMatch = text.match(/progress\s*=\s*(\d+)%/)
          if (progMatch) {
            const localPct = parseInt(progMatch[1], 10)
            const overallElapsed = seg.startSec + (localPct / 100) * seg.durationSec
            const overallPct = 2 + Math.round((overallElapsed / totalDuration) * 96)
            send(win, {
              phase: 'transcribing',
              percent: overallPct,
              message: `Transcribing... (segment ${seg.index + 1} of ${segments.length})`,
              elapsed: overallElapsed,
              totalDuration,
              useGpu: gpuEnabled
            })
          }
        })

        // whisper-cli writes recognized text segments to stdout
        const seenTimestamps = new Set<string>()
        whisperProc.stdout?.on('data', (chunk: Buffer) => {
          const text = chunk.toString()
          for (const line of text.split('\n')) {
            const segMatch = line.match(/\[([\d:.,]+)\s*-->\s*[\d:.,]+\]\s+(.+)/)
            if (segMatch) {
              const localTimestamp = segMatch[1]
              if (seenTimestamps.has(localTimestamp)) continue
              seenTimestamps.add(localTimestamp)

              const localElapsed = hhmmssToSeconds(localTimestamp.replace(',', '.'))
              const overallElapsed = seg.startSec + localElapsed
              const overallPct = 2 + Math.min(Math.round((overallElapsed / totalDuration) * 96), 96)

              send(win, {
                phase: 'transcribing',
                percent: overallPct,
                text: segMatch[2].trim(),
                segmentTimestamp: secondsToTimestamp(overallElapsed),
                elapsed: overallElapsed,
                totalDuration,
                useGpu: gpuEnabled
              })
            }
          }
        })

        whisperProc.on('close', (code) => {
          signal.removeEventListener('abort', onAbort)
          activeProcess = null
          if (signal.aborted) { resolve(); return }
          if (code === 0) resolve()
          else reject(new Error(`Whisper failed on segment ${seg.index + 1} (code ${code})`))
        })
        whisperProc.on('error', reject)
      })

      // Read offset SRT content, then delete the segment WAV immediately to free space
      const segSrtPath = `${segSrtBase}.srt`
      try {
        const rawSrt = readFileSync(segSrtPath, 'utf-8')
        srtContents.push(offsetSrtContent(rawSrt, seg.startSec))
      } catch {
        // Segment produced no output (e.g. silent segment) — skip it
      }
      await unlink(segWavPath).catch(() => {})
    }

    // ── Merge and write final SRT ─────────────────────────────────────────────
    const mergedSrt = mergeSrts(srtContents)
    writeFileSync(srtPath, mergedSrt, 'utf-8')

    // Clean up the full WAV (segment WAVs already deleted above)
    await unlink(fullWavPath).catch(() => {})

    send(win, { phase: 'done', percent: 100, message: 'Transcription complete!', srtPath })
    return srtPath
  } catch (err) {
    const isCancelled = signal.aborted || (err instanceof Error && err.message === 'Cancelled')
    if (!isCancelled) {
      send(win, {
        phase: 'error',
        percent: 0,
        errorMessage: err instanceof Error ? err.message : String(err)
      })
    }
    throw err
  } finally {
    if (activeAbortController === abortController) {
      activeAbortController = null
    }
    activeProcess = null
    if (tempDir) cleanupTempDir(tempDir)
  }
}

export function cancelTranscription(): void {
  activeAbortController?.abort()
  if (activeProcess) {
    activeProcess.kill('SIGTERM')
    activeProcess = null
  }
}
